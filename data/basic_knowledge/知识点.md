# point

## 上溢和下溢

***下溢***：接近于0的数当四舍五入为0时，可能会发生下溢。当出现**除以**一个数，或者对一个数取**对数**等情况时，需要非常注意来避免下溢。

***上溢***：当一个大量级的数被近似为$\infty$或者$-\infty$时，称为上溢。

举一个例子，softmax函数：

$$softmax(x_i)=\frac{e^{x_i}}{\sum_{j=1}^n e^{x_j}}$$

当$x_i=c, i=1,2,...,n$，$c$为一个常数时，我们期望所有$x_i$的函数值都为$\frac{1}{n}$，但是当$c$是一个非常小的负数时，$e^c$可能取值为0（即发生下溢），这个时候softmax函数的分母就会变为0，使得求值发生错误。当$c$为一个非常大的正数时，$e^c$会趋近于$\infty$，这个时候会发生上溢。

对于softmax函数来说，我们可以使$x=x-max_i{x_i}$，来避免溢出，因为经过该操作以后，向量$x$中最大的数为0（避免上溢），此时我们可以保证分母不为0（避免求幂后下溢）。

除此之外分子还有可能出现下溢（等于0）的情况，若我们下一步进行对数计算，即$log softmax$，会错误的得到$-\infty$。

通常情况下，我们在实际的应用中不会考虑太多数值计算产生的溢出问题（尤其是下溢，因为计算机的浮点数运算几乎不会算出严格等于0的情况），但是对于底层库的开发者来说这很重要。

## 条件数

条件数是指一个函数相对于输入的*微小*变化而变化的*快慢程度*。

例如说对于函数$f(x)=A^{-1}x$，当$A \in \mathbb{R}^{n \times n}$具有特征分解时，其条件数是$max_{i,j}|\frac{\lambda_i}{\lambda_j}|$，该值越大$f(x)$对输入数据的变化越敏感。

这种敏感性是系统本身固有的，而不是由于求逆时引入的误差。而在实际运算过程中，条件数越大的函数会导致输入的微小误差产生严重的后果。

